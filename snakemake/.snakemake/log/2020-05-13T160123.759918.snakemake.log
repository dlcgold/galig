The flag 'directory' used in rule all is only valid for outputs, not inputs.
Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	splitAnnotation
	1

[Wed May 13 16:01:23 2020]
rule splitAnnotation:
    input: data/annotation21.gtf, data
    output: data/annotations.txt
    jobid: 0

[Wed May 13 16:01:25 2020]
Error in rule splitAnnotation:
    jobid: 0
    output: data/annotations.txt

RuleException:
CalledProcessError in line 65 of /home/dlcgold/stage-unimib/extra/snake/Snakefile:
Command 'set -euo pipefail;  /usr/bin/python /home/dlcgold/stage-unimib/extra/snake/.snakemake/scripts/tmph2nat4j3.splitGene.py' returned non-zero exit status 1.
  File "/home/dlcgold/stage-unimib/extra/snake/Snakefile", line 65, in __rule_splitAnnotation
  File "/usr/lib/python3.8/concurrent/futures/thread.py", line 57, in run
Removing output files of failed job splitAnnotation since they might be corrupted:
data/annotations.txt
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/dlcgold/stage-unimib/extra/snake/.snakemake/log/2020-05-13T160123.759918.snakemake.log
