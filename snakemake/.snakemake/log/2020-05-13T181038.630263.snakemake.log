Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	downloadAnnotation
	1	downloadGenome
	1	extractAnnotation
	4

[Wed May 13 18:10:38 2020]
rule downloadAnnotation:
    output: data/annotation.gtf
    jobid: 3


[Wed May 13 18:10:38 2020]
rule downloadGenome:
    output: data/chr21.fa
    jobid: 1

Terminating processes on user request, this might take some time.
[Wed May 13 18:10:43 2020]
Error in rule downloadAnnotation:
    jobid: 3
    output: data/annotation.gtf
    shell:
        
        wget -O - ftp://ftp.ensembl.org/pub/release-100/gtf/homo_sapiens/Homo_sapiens.GRCh38.100.chr.gtf.gz | gunzip > data/annotation.gtf
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
[Wed May 13 18:10:43 2020]

Error in rule downloadGenome:
Removing output files of failed job downloadAnnotation since they might be corrupted:
data/annotation.gtf
    jobid: 1
    output: data/chr21.fa
    shell:
        
        wget -O - ftp://ftp.ensembl.org/pub/release-100/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.chromosome.21.fa.gz | gunzip > data/chr21.fa
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Removing output files of failed job downloadGenome since they might be corrupted:
data/chr21.fa
Complete log: /home/dlcgold/stage-unimib/extra/snake/.snakemake/log/2020-05-13T181038.630263.snakemake.log
